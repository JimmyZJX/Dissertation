
\section{Overview}

In this chapter, we present a worklist algorithm
that further supports subtyping,
by introducing the top and bottom types.
Such type inference algorithms are known to be hard to design,
due to the complication of unifying variables under subtyping inequality
rather than equality.
Therefore, algorithmic existential variables that appear in subtyping judgments
might have more solutions than before,
and the eager substitution rules miss some possibilities.
Our new \emph{backtracking} algorithm extends the existing one by some overlapping rules that
non-deterministically try different sorts of solutions instead of a single sort,
improving the rate of success guessing.

Formalization of the algorithm in the Abella theorem prover shows soundness of the algorithm
with respect to our declarative specification.
Although the backtracking algorithm is still incomplete in some corner cases,
the proof script indicates that the only source of incompleteness comes from
higher-ranked subtyping relations.
Following that discovery, we formally proved partial completeness of our subtyping algorithm
under the rank-1 restriction,
and is at least comparable to local type inference algorithms.

\subsection{Type Inference in Presence of Subtyping}

In all previous chapters, ``subtyping'' refers to a relationship that compares
the degree of polymorphism between two types.
In addition to that, we also include the top and bottom types.
Both of the types have practical uses, especially in object-oriented programming languages.
The top type, $\top$, is the super type of any type,
i.e. any type is more general than $\top$
and thus can be considered as an instance of type $\top$.
In typical object-oriented programming languages, the \texttt{Object} class,
as the base class of any class, is the $\top$ type.
In contrast, the bottom type, $\bot$, is dual to $\top$.
An instance of $\bot$ can be cast to a value of any type,
which is also viewed as the uninhabited type therefore
one cannot find any value that has the $\bot$ type.
However, there are few exceptions.
One of them is a \texttt{null pointer} value (\texttt{(void *)} in C++, for example).
Another practical use for bottom types is for exceptions.
The type $\text{Exception} \to \bot$ given to the \texttt{raise}
function may pass type checkers naturally.
The type $\text{Exception} \to \all a$ is also a reasonable choice,
which in fact reveals that $\bot$ behaves almost identically as $\all a$.
From the theoretical point of view, both of them represent ``falsity''.



A number of systems and algorithms are proposed for type inference with subtyping.
Since subtyping constraints cannot be easily reduced in presence of subtyping,
it is natural to extend the syntax of types so that unsolved constraints are carried with them,
and the idea is studied by previous work~\citep{RecConstraint1995, subcon1996}.
For example, the following function
\begin{verbatim}
select p v d = if (p v) then v else d
\end{verbatim}
is inferred to have the type
$$(\alpha \to \text{bool}) \to \alpha \to \beta \to \gamma \mid \alpha \le \gamma, \beta \le \gamma$$
However, this representation usually contains a large set of constraints,
which might confuse programmers.
Besides, subtyping comparison between constraint types may introduce additional
difficulty for programmers to understand, which weakens its practical use.

\paragraph{MLsub}
MLsub~\citep{mlsub}, as introduced in Section~\ref{sec:mlsub},
is based on a type system with lattices and polar types.
Inspired by~\citep{pottier1998phd}, they separated input and output types into polar types,
which greatly simplifies the subtyping judgment.
With the further help of their biunification algorithm,
constraints are no longer carried with types,
instead they are expressed directly on types.
For example, the \verb|select| function defined above has type
$$(\alpha \to \text{bool}) \to \alpha \to \beta \to \alpha \sqcup \beta$$
in MLsub.
The $\sqcup$ symbol in the output type indicates that
any of the types might be returned when executed.
On the other hand, the $\sqcap$ symbol might occur on an input type,
when that argument is used as different types,
meaning that the type must be able to convert to all these types.

Nevertheless, there are still drawbacks in practice.
Firstly, the type inference algorithm produces types that
have comparable sizes to previous systems with constraint types.
Although a simplification algorithm is provided,
it is not guaranteed to produce the most simple form.

Secondly, MLsub always infers an expression and returns its principal type,
but some of the types are not easy to understand.
For example, the \verb|twice| function defined as
\begin{verbatim}
  twice f x = f (f x)
\end{verbatim}
has type $(\alpha \sqcup \beta \to \alpha) \to \beta \to \alpha$,
where normally people might expect $(\alpha \to \alpha) \to \alpha \to \alpha$.

Thirdly, MLsub tries to infer on almost every possible expression,
even those that might just be a mistake made by the programmer.
For instance, the function
\begin{verbatim}
  positive f x = if x > 0 then f x else f 0
\end{verbatim}
always checks the positivity of \verb|x| before applying to \verb|f|.
However, a slight mistake is made in the following definition
\begin{verbatim}
  positive' f x = if x > 0 then f x else f
\end{verbatim}
then the algorithm might still accept the program by giving the type:
$$\alpha \sqcap (\beta \to \alpha) \to \beta \sqcap \text{int} \to \alpha$$
Type inference algorithms, as logical tools that help people program,
should accept good programs and reject bad ones.
Typically, such a function is considered to be badly-written,
but unfortunately, MLsub accepts it without giving any warnings.

\subsection{Judgment List and Eager Substitution}

The judgment list algorithm we discussed in the last chapter treats subtyping
judgments mainly as unification.
However, the algorithm may lose some solutions
when top and bottom types are introduced.
For example,
the judgment $\al \le 1$ has the best solution
$\al := 1$ in the previous system,
but now $\al := \bot$ should also be allowed.
As a result, several subtyping judgments cannot be reduced easily with a single
eager substitution.

Similar incompleteness also affects the instantiation and
existential variable solving rules
\begin{gather*}
\begin{aligned}
    \Gm[\al] \Vdash \al \le A\to B &\rrule{10} [\al[1]\to\al[2]/\al] (\Gm[\al[1], \al[2]] \Vdash \al[1]\to \al[2] \le A \to B)\\
    \Gm[\al][\bt] \Vdash \al \le \bt &\rrule{12} [\al/\bt](\Gm[\al][])
\end{aligned}
\end{gather*}
The instantiation judgment $\al \le A \to B$ immediately split $\al$ into $\al[1] \to \al[2]$,
which is no longer the case --- $\al$ can also be $\bot$.

The rule that solves one existential variable against another,
$\al \le \bt$, is even more problematic,
because the shapes of the instantiations of both existential variables are unknown,
there are infinitely many possibilities if no additional constraints present.
For example, if $\al$ is finally instantiated to $\text{Int} \to \text{Int}$,
then $\bt$ may be solved to the same type as $\al$,
or other types that satisfy the subtyping relationship,
including $\text{Int} \to \top$, $\bot \to \text{Int}$ or $\bot \to \top$.
What's worse, given only this single subtyping judgment $\al \le \bt$,
we have no assumption on both existential variables.

Theoretically speaking, if we extend the type system with $\top$ and $\bot$ types,
the definition of monotypes becomes
\[ \tau ::= 1 \mid \bot \mid \top \mid \tau \to \tau \mid a\]
, which causes the subtyping problem to be undecidable~\cite{su2002firstorder}.
Therefore, it is impossible to derive a complete algorithm for the declarative system,
and we try to keep the algorithm complete for common usages of polymorphism,
but pose restrictions in some higher-ranked cases.

% \subsection{Lazy Substitution and Non-terminating Loops}
% discussed later


\subsection{Our Solution: Backtracking Algorithm}

After examining the examples where the worklist algorithm behaves incompletely,
we propose some improvements to the worklist algorithm to accept some simple cases.
We have observed that subtyping judgments like $\al \le A$ and $A \le \al$ have trivial solutions
$\al := \bot$ and $\al := \top$ respectively,
thus we can try these simple solutions before the more complicated analysis.

For example, for the judgment list $\Gm \Vdash \al \le A \to B$,
we first assign $\al := \bot$ and continue to check other judgments.
If the judgment reduction succeeds, then we know that $\al := \bot$ is a possible solution.
If the reduction failed, we continue to try the other possibility according to the
previous instantiation rule by splitting $\al$ into two existential variables $\al[1]$ and $\al[2]$.
The procedure must keep track of all backtracking points until type-checking the whole program.
Note that for the reduced judgment $\al[1] \to \al[2] \le A \to B$,
$\al[1]$ and $\al[2]$ might be solved to $\top$ or $\bot$.

For the type system, there are also interesting changes to
both the declarative system and algorithmic system.
Two algorithmic typing rules also adopt the backtracking approach:
\begin{itemize}
    \item The checking judgment $e \Lto \al$ now has a trivial solution $\al := \top$,
        because $e \Lto \top$ should be accepted for any (well-formed) expression.
    \item The introduction of top and bottom types comes with another new declarative rule
        $\appInf{\bot}{e}{\bot}$.
        Therefore the application inference judgment $\appInfAlg{\al}{e}$
        can be satisfied by $\al := \bot$,
        with output $\bot$ applied to the rest of the judgment chain $\jg$.
\end{itemize}

By applying the above modifications,
the algorithm remains sound w.r.t our new declarative system,
and at the same time, we address most issues regarding the top and bottom types,
obtaining a more complete algorithm.
Furthermore, we formally verified that the subtyping algorithm
is complete under the rank-1 restriction.
However, for rank-2 judgments like $\al \le \bt$,
a naive complete algorithm would traverse an infinitely large tree of possibilities
and diverge for some set of constraints.
% completeness is impossible for any algorithm that reduces eagerly.

Following the formal statements, we conclude that the backtracking algorithm
is complete under a rank-1 restriction, but not always on the general higher-ranked settings.
In those settings, our algorithm only consider the equality case and ignore any other possibilities.
In another perspective, our algorithm does not try to solve completely when
parametric polymorphism and subtyping polymorphism occur at the same time.
This is not theoretically satisfactory, but we argue that
this handles most common programs, and the programmer may use annotation to guide
the inference algorithm with the real type he intends to instantiate.


